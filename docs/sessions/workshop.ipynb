{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This version: 26 June 2020*\n",
    "\n",
    "Comments: h.datta@tilburguniversity.edu\n",
    "\n",
    "**Requires Python 3.x**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation requirements\n",
    "Please install the following packages through pip:\n",
    "\n",
    "```\n",
    "pip install selenium\n",
    "```\n",
    "\n",
    "You also need a *current version of Chrome and chromedriver*; for setup instructions, see http://tilburgsciencehub.com/setup/webscraping_drivers/.\n",
    "\n",
    "**Only then will you be able to proceed to the next cells.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages into memory\n",
    "import urllib\n",
    "import datetime\n",
    "\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# Function to clean text from extra characters (e.g., new line characters, tabs)\n",
    "def cleanstring(obj):\n",
    "    return(re.sub(r\"[\\n\\t\\s]*\", \"\", obj))\n",
    "\n",
    "# Function to create a new directory if it does not exist yet\n",
    "def makedir(dirname):\n",
    "    try:\n",
    "        os.stat(dirname)\n",
    "    except:\n",
    "        os.mkdir(dirname)\n",
    "        \n",
    "# Function to generate filename based on time of the computer\n",
    "def timestamp_to_string(prefix='', extention='.html'):\n",
    "    return(prefix+str(time.time()).replace('.','-')+extention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1) Simple HTTP requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) requests - without header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('http://www.amazon.com', headers={})\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show \"content\"\n",
    "r.text[1:1000]\n",
    "\n",
    "# --> looks like a website!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's save website to HTML file and open it!\n",
    "makedir('module1/')\n",
    "f=open('module1/amazon.html','w', encoding='utf-8') # utf-8 is extremely important (!)\n",
    "f.write(r.text)\n",
    "f.close()\n",
    "\n",
    "# hm... looks like they realized we're trying to scrape!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) requests - with header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could try pretending we're a Chrome Browser on an iPhone (!)\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 10_3 like Mac OS X) AppleWebKit/602.1.50 (KHTML, like Gecko) CriOS/56.0.2924.75 Mobile/14E5239e Safari/602.1'}\n",
    "\n",
    "r = requests.get('http://www.amazon.com', headers=headers)\n",
    "f=open('module1/amazon_mobile.html','w', encoding='utf-8') # utf-8 is extremely important (!)\n",
    "f.write(r.text)\n",
    "f.close()\n",
    "\n",
    "# --> compare the files!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) selenium - remote controlling chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start up the browser - once!\n",
    "browser = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's navigate to a page\n",
    "browser.get('https://amazon.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the page\n",
    "makedir('module1/')\n",
    "\n",
    "f=open('module1/amazon_selenium.html','w', encoding='utf-8')\n",
    "f.write(browser.page_source)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Your turn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write some code to open, after one another, the following category pages at Amazon.\n",
    "Do you use `requests` or `selenium's webdriver`?\n",
    "\n",
    "urls = ['https://www.amazon.com/s?bbn=16225007011&rh=n%3A16225007011%2Cn%3A172456&dc&fst=as%3Aoff&qid=1593153247&rnid=16225007011&ref=lp_16225007011_nr_n_0',\n",
    "'https://www.amazon.com/s?bbn=16225007011&rh=n%3A16225007011%2Cn%3A193870011&dc&fst=as%3Aoff&qid=1593153269&rnid=16225007011&ref=lp_16225007011_nr_n_1',\n",
    "'https://www.amazon.com/s?bbn=16225007011&rh=n%3A16225007011%2Cn%3A13896617011&dc&fst=as%3Aoff&qid=1593153269&rnid=16225007011&ref=lp_16225007011_nr_n_2']\n",
    "\n",
    "Pause your code for 2 seconds after each requests, using\n",
    "```\n",
    "import time\n",
    "time.sleep(2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2) Simple HTTP requests to an API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the current VAT rate in the EU\n",
    "url = 'https://mixer.com/api/v1/channels'\n",
    "data = requests.get(url, headers={})\n",
    "data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: Extracting data from JSON objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load JSON objects\n",
    "f=requests.get('https://hannesdatta.github.io/course-jads2020/sessions/json_objects.json').text.split('\\n')\n",
    "\n",
    "postcode = json.loads(f[0])\n",
    "spotify = json.loads(f[1])\n",
    "twitter = json.loads(f[2])\n",
    "mixer = json.loads(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example:\n",
    "print('Source: ' + twitter.get('source'))\n",
    "print('User name: ' + twitter.get('user').get('name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter.get('user').get('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mixer:\n",
    "    name=i.get('token')\n",
    "    followers=i.get('numFollowers')\n",
    "    print(name + ': ', str(followers), ' followers.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4: Extracting data from HTML objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get page\n",
    "browser=webdriver.Chrome()\n",
    "browser.get('https://www.amazon.com/First-Years-Stack-Up-Cups/dp/B00005C5H4/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "css='#averageCustomerReviews_feature_div > div:nth-child(2) > span:nth-child(3) > a:nth-child(1) > span:nth-child(1)'\n",
    "print(browser.find_element_by_css_selector(css).text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5: Looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://spotifycharts.com/regional/nl/daily/2020-06-23/download'\n",
    "header = {\"User-Agent\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:65.0) Gecko/20100101 Firefox/65.0'}\n",
    "r = requests.get(url, headers=header)\n",
    "makedir('module5/')\n",
    "f=open('module5/spotify-nl.csv', 'w',encoding= 'utf-8')\n",
    "f.write(r.text)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a loop that iterates through any given day..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date1 = '2020-06-01'\n",
    "date2 = '2020-06-20'\n",
    "mydates = pd.date_range(date1, date2).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the dates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a loop around our scraping code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for mydate in mydates:\n",
    "    new_date = str(mydate.date())\n",
    "    url = 'https://spotifycharts.com/regional/nl/daily/'+new_date+'/download'\n",
    "    print(url)\n",
    "    r = requests.get(url, headers=header)\n",
    "    f=open('module5/spotify-nl-'+ new_date+ '.csv', 'w',encoding= 'utf-8')\n",
    "    f.write(r.text)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 6: Modularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a bit of setup code\n",
    "makedir('module6/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's wrap our scraping code in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_spotify(country, date, path=''):\n",
    "    url = 'https://spotifycharts.com/regional/'+country+'/daily/' + date+ '/download'\n",
    "    print(url)\n",
    "    header = {\"User-Agent\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:65.0) Gecko/20100101 Firefox/65.0'}\n",
    "    r = requests.get(url, headers=header)\n",
    "    fn = path+'spot_'+country+'_'+date+'.csv'\n",
    "    f=open(fn, 'w',encoding= 'utf-8')\n",
    "    f.write(r.text)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's run it!\n",
    "scrape_spotify('nl', '2018-01-01', path = 'module6/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rewrap it in a loop - it's now way easier to spot what's going on. Plus we can extend the countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = ['nl', 'us']\n",
    "date1 = '2020-06-01'\n",
    "date2 = '2020-06-20'\n",
    "mydates = pd.date_range(date1, date2).tolist()\n",
    "new_date = str(mydate.date())\n",
    "\n",
    "for country in countries:\n",
    "    for mydate in mydates:\n",
    "        scrape_spotify(country, str(mydate.date()), 'module6/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
