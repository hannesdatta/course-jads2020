{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome! Welcome to the course page for \"Web scraping/APIs & efficient workflows for data- and computation-intensive projects\", which will be online to students of the DEP program at JADS 's-Hertogenbosch in May and June 2020. Save the date Session 1: Efficient workflows for data- and computation-intensive projects Date: 29 May 2020, 13.30 - 17.00 Session 2: \"Web scraping/APIs\" Date: 26 June 2020, 09.00 - 12.30 My course features a mix of tutorials to prepare beforehand, and live-streamed lectures and interactive computer labs. This material will get you started in managing data- and computation-intensive projects efficiently, and using web scraping (i.e., the automatic extraction of information from publicly accessible websites) and Application Protocol Interfaces (APIs, i.e., a more structured way to obtain data from online sources) for your own data science projects. I have set up this site so that you can optimally prepare for the sessions. The site is work-in-progress, and will be updated once we get closer to the actual date. What's next Check out the syllabus and how to prepare for each session (\u2192 syllabus ) Carefully go through the setup procedure for your computer, and verify that R , python , and make are callable from the command line/terminal (\u2192 setup guide ) Read a bit about your instructor (\u2192 about the instructor )","title":"Home"},{"location":"#welcome","text":"Welcome to the course page for \"Web scraping/APIs & efficient workflows for data- and computation-intensive projects\", which will be online to students of the DEP program at JADS 's-Hertogenbosch in May and June 2020. Save the date Session 1: Efficient workflows for data- and computation-intensive projects Date: 29 May 2020, 13.30 - 17.00 Session 2: \"Web scraping/APIs\" Date: 26 June 2020, 09.00 - 12.30 My course features a mix of tutorials to prepare beforehand, and live-streamed lectures and interactive computer labs. This material will get you started in managing data- and computation-intensive projects efficiently, and using web scraping (i.e., the automatic extraction of information from publicly accessible websites) and Application Protocol Interfaces (APIs, i.e., a more structured way to obtain data from online sources) for your own data science projects. I have set up this site so that you can optimally prepare for the sessions. The site is work-in-progress, and will be updated once we get closer to the actual date.","title":"Welcome!"},{"location":"#whats-next","text":"Check out the syllabus and how to prepare for each session (\u2192 syllabus ) Carefully go through the setup procedure for your computer, and verify that R , python , and make are callable from the command line/terminal (\u2192 setup guide ) Read a bit about your instructor (\u2192 about the instructor )","title":"What's next"},{"location":"about/","text":"About the instructor Hi, I'm Hannes Datta, an Associate Professor of Marketing at Tilburg University. I develop advanced econometric models that guide managerial decision-making and inform public policy in the area of digital media consumption (e.g., on streaming services, on digital TV), branding, and retailing. Next to my research , I have a passion for teaching, and have won several teaching awards in the past years (among others, Tilburg University's Teacher of the Year Award). For my research, I make use of web scraping and API technology, and that's also how the inaugural (2019) version of this course was born. Recently, I have launched an initiative to enhance research productivity by designing efficient workflows to manage data- and computation-intensive projects. That's also why I use this new site and brand-new tutorials throughout this course. The site is open-source, by the way, so feel free to contribute to it! You can best reach me (for short questions) via WhatsApp, on +31134668938. More formal inquiries should be emailed . Web: https://tiu.nu/datta and http://www.datta-online.com LinkedIn: https://www.linkedin.com/in/hannes-datta/ Twitter: https://twitter.com/hannesdatta Email: h.datta@tilburguniversity.edu","title":"About the instructor"},{"location":"about/#about-the-instructor","text":"Hi, I'm Hannes Datta, an Associate Professor of Marketing at Tilburg University. I develop advanced econometric models that guide managerial decision-making and inform public policy in the area of digital media consumption (e.g., on streaming services, on digital TV), branding, and retailing. Next to my research , I have a passion for teaching, and have won several teaching awards in the past years (among others, Tilburg University's Teacher of the Year Award). For my research, I make use of web scraping and API technology, and that's also how the inaugural (2019) version of this course was born. Recently, I have launched an initiative to enhance research productivity by designing efficient workflows to manage data- and computation-intensive projects. That's also why I use this new site and brand-new tutorials throughout this course. The site is open-source, by the way, so feel free to contribute to it! You can best reach me (for short questions) via WhatsApp, on +31134668938. More formal inquiries should be emailed . Web: https://tiu.nu/datta and http://www.datta-online.com LinkedIn: https://www.linkedin.com/in/hannes-datta/ Twitter: https://twitter.com/hannesdatta Email: h.datta@tilburguniversity.edu","title":"About the instructor"},{"location":"schedule/","text":"Schedule The course will be taught on two days. The schedule will be updated once we approach the course. Session 1: Efficient workflows for data- and computation-intensive projects Date: 29 May 2020, 13.30 - 17.00 13.30 - 14.30 tba 14.45 - 15:45 tba 16.00 - 17:00 tba Session 2: \"Web scraping/APIs\" Date: 26 June 2020, 09.00 - 12.30 09.00 - 10.00 tba 10.15 - 11:15 tba 11:30 - 12:30 tba","title":"Schedule"},{"location":"schedule/#schedule","text":"The course will be taught on two days. The schedule will be updated once we approach the course. Session 1: Efficient workflows for data- and computation-intensive projects Date: 29 May 2020, 13.30 - 17.00 13.30 - 14.30 tba 14.45 - 15:45 tba 16.00 - 17:00 tba Session 2: \"Web scraping/APIs\" Date: 26 June 2020, 09.00 - 12.30 09.00 - 10.00 tba 10.15 - 11:15 tba 11:30 - 12:30 tba","title":"Schedule"},{"location":"syllabus/","text":"Course syllabus Session 1: Efficient Workflows for Data- and Computation-intensive Projects Learning Objectives Review the key building blocks of efficient workflows, following tilburgsciencehub.com e.g., understand the concept of project pipelines and project components, and how they apply to your own research project e.g., learn about the benefits of automating your project's pipeline Replicate a reproducible workflow for enriching JSON data from Twitter with text mining metrics, and producing an RMarkdown document with results. Discuss and implement advanced workflows to manage complex computational projects Adhere to a grow-as-you go directory structure to keep source code organized Learn how to automate your project infrastructure using make Integrate cloud storage from AWS S3, Google Drive, or Dropbox Version your project's source code and manage Issues/To do's using Git/GitHub Collaborate on open source projects Formulate steps to professionalize data and code management in your own research projects Preparation To be able to follow the class, you need to prepare the following things: Setup your computer, following our installation guide . Please install: Python 3.x via Anaconda R >= 3.x and RStudio GNU Make It is important that these software tools are callable from the command line/terminal. Mac users: try whether running python , R and make from the terminal works. Windows users: please configure your environment variables so that you can call python , R and make from Anaconda Prompt . Familiarize yourself with http://tilburgsciencehub.com . In particular, browse our section where we document the basics of efficient workflow design explore the various other sections of the website Follow our tutorial to implement a basic automated workflow to enrich JSON data with text mining metrics. Please allow sufficient time to follow this tutorial (approx. 4 hours should suffice, if you have the software setup right). Be prepared to show the directory of a recent project you\u2019re working on \u2013 be able to explain that structure (you don\u2019t need to revise the structure before class!) Session 2: Web scraping and APIs Learning Objectives Overview about the domain of online data collections Introduce you to web scraping and APIs: what are they, exactly, and what are commonalities and differences? Understand the basics of web technology Explain the difference between structured (e.g., Excel files, SQL databases) and unstructured data bases (e.g., MongoDB, JSON objects) Identify relevant (open) databases, websites and APIs that can be useful for your own research projects Explain the data context of your own research Understand data retrieval strategies: forward looking versus backward looking Decide on what information to retrieve: identifying CSS selectors and API endpoints Seeding strategies in online data collections Legal aspects of online data collections Enable you to make the first steps in scraping a website of your choice Preparation Warning Likely to be updated soon. Watch an introduction video to web scraping and APIs (~20 minutes): what are they, what can they be used for? Think about which online data may be useful for your own research; be able to show the website, database or API to everyone in class. Set up your own laptop for in-class exercises On top of the software stack for Session #1, you need to install the \"web scraping tools\"; details are available on https://tilburgsciencehub.com/setup/webscraping Browse my article on how Spotify has changed music consumption . Pay close attention to the data section. Go through the web scraping tutorial (will be made available later).","title":"Syllabus and Preparation"},{"location":"syllabus/#course-syllabus","text":"","title":"Course syllabus"},{"location":"syllabus/#session-1-efficient-workflows-for-data-and-computation-intensive-projects","text":"","title":"Session 1: Efficient Workflows for Data- and Computation-intensive Projects"},{"location":"syllabus/#learning-objectives","text":"Review the key building blocks of efficient workflows, following tilburgsciencehub.com e.g., understand the concept of project pipelines and project components, and how they apply to your own research project e.g., learn about the benefits of automating your project's pipeline Replicate a reproducible workflow for enriching JSON data from Twitter with text mining metrics, and producing an RMarkdown document with results. Discuss and implement advanced workflows to manage complex computational projects Adhere to a grow-as-you go directory structure to keep source code organized Learn how to automate your project infrastructure using make Integrate cloud storage from AWS S3, Google Drive, or Dropbox Version your project's source code and manage Issues/To do's using Git/GitHub Collaborate on open source projects Formulate steps to professionalize data and code management in your own research projects","title":"Learning Objectives"},{"location":"syllabus/#preparation","text":"To be able to follow the class, you need to prepare the following things: Setup your computer, following our installation guide . Please install: Python 3.x via Anaconda R >= 3.x and RStudio GNU Make It is important that these software tools are callable from the command line/terminal. Mac users: try whether running python , R and make from the terminal works. Windows users: please configure your environment variables so that you can call python , R and make from Anaconda Prompt . Familiarize yourself with http://tilburgsciencehub.com . In particular, browse our section where we document the basics of efficient workflow design explore the various other sections of the website Follow our tutorial to implement a basic automated workflow to enrich JSON data with text mining metrics. Please allow sufficient time to follow this tutorial (approx. 4 hours should suffice, if you have the software setup right). Be prepared to show the directory of a recent project you\u2019re working on \u2013 be able to explain that structure (you don\u2019t need to revise the structure before class!)","title":"Preparation"},{"location":"syllabus/#session-2-web-scraping-and-apis","text":"","title":"Session 2: Web scraping and APIs"},{"location":"syllabus/#learning-objectives_1","text":"Overview about the domain of online data collections Introduce you to web scraping and APIs: what are they, exactly, and what are commonalities and differences? Understand the basics of web technology Explain the difference between structured (e.g., Excel files, SQL databases) and unstructured data bases (e.g., MongoDB, JSON objects) Identify relevant (open) databases, websites and APIs that can be useful for your own research projects Explain the data context of your own research Understand data retrieval strategies: forward looking versus backward looking Decide on what information to retrieve: identifying CSS selectors and API endpoints Seeding strategies in online data collections Legal aspects of online data collections Enable you to make the first steps in scraping a website of your choice","title":"Learning Objectives"},{"location":"syllabus/#preparation_1","text":"Warning Likely to be updated soon. Watch an introduction video to web scraping and APIs (~20 minutes): what are they, what can they be used for? Think about which online data may be useful for your own research; be able to show the website, database or API to everyone in class. Set up your own laptop for in-class exercises On top of the software stack for Session #1, you need to install the \"web scraping tools\"; details are available on https://tilburgsciencehub.com/setup/webscraping Browse my article on how Spotify has changed music consumption . Pay close attention to the data section. Go through the web scraping tutorial (will be made available later).","title":"Preparation"}]}