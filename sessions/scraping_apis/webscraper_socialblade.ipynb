{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This version: 3 June 2020*\n",
    "\n",
    "Comments: h.datta@tilburguniversity.edu\n",
    "\n",
    "**Requires Python 3.x**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation requirements\n",
    "Please install the following packages through pip:\n",
    "\n",
    "```\n",
    "pip install lxml\n",
    "pip install selenium\n",
    "pip install cssselect\n",
    "```\n",
    "\n",
    "You also need a *current version of Chrome and chromedriver*; for setup instructions, see http://tilburgsciencehub.com/setup/webscraping_drivers/.\n",
    "\n",
    "**Only then will you be able to proceed to the next cells.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**ATTENTION:**</font> Recall that by the time you're running this notebook, the website we're using in this example may have changed its layout. So don't be surprised if some of the CSS selectors we use in the examples don't work anymore. Instead, directly debub the CSS selector by opening Chrome, navigating to the website, and opening the Developer Tools to copy the CSS selector of your desired target element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages into memory\n",
    "import urllib\n",
    "import datetime\n",
    "from lxml import etree \n",
    "from lxml.cssselect import CSSSelector\n",
    "from lxml.etree import fromstring\n",
    "\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import codecs\n",
    "\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "import io\n",
    "import json\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# Function to clean text from extra characters (e.g., new line characters, tabs)\n",
    "def cleanstring(obj):\n",
    "    return(re.sub(r\"[\\n\\t\\s]*\", \"\", obj))\n",
    "\n",
    "# Function to create a new directory if it does not exist yet\n",
    "def makedir(dirname):\n",
    "    try:\n",
    "        os.stat(dirname)\n",
    "    except:\n",
    "        os.mkdir(dirname)\n",
    "        \n",
    "# Function to generate filename based on time of the computer\n",
    "def timestamp_to_string(prefix='', extention='.html'):\n",
    "    return(prefix+str(time.time()).replace('.','-')+extention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Building a web scraper for Socialblade.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you've seen before was just a starter. Here, we use proper machinery - read, packages - that help us get the data we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Introducing you to chromedriver (\"What you see is what you get!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we use a web driver provided by Internet browser Chrome (\"chromedriver\"), in combination with a really powerful Python package called selenium. Using this package will help us to actually retrieve parts of the page. The setup instructions for Chromedriver are on top of this document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first open the browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magic, huh? Now let's direct it to a page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.get('https://socialblade.com/youtube/user/enzoknol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could now build a loop to extract the number of video views...\n",
    "\n",
    "Let's first see whether we have the right CSS selector for these views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "€11.3K - €180.5K\n"
     ]
    }
   ],
   "source": [
    "print(browser.find_element_by_css_selector('#socialblade-user-content > div:nth-child(3) > div:nth-child(2) > p:nth-child(1)').text)\n",
    "#print(browser.find_element_by_css_selector('#socialblade-user-content > div:nth-child(3) > div:nth-child(3) > p:nth-child(1)').text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a loop and save the data in a JSON object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a loop and writing to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enzoknol\n",
      "officialtrapcity\n",
      "martingarrix\n",
      "rtlthevoice\n"
     ]
    }
   ],
   "source": [
    "users = ['enzoknol', 'officialtrapcity', 'martingarrix', 'rtlthevoice']\n",
    "#users = ['enzoknol', 'hannesd84']\n",
    "\n",
    "f = open('scraping-output.csv', 'w', encoding='utf-8')\n",
    "f.write('username\\tyearlyincome\\n')\n",
    "\n",
    "for i in users:\n",
    "    print(i)\n",
    "    browser.get('http://www.socialblade.com/youtube/user/'+i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        yearlyincome = browser.find_element_by_css_selector('#socialblade-user-content > div:nth-child(3) > div:nth-child(2) > p:nth-child(1)').text\n",
    "    except:\n",
    "        yearlyincome = 'NA'\n",
    "        \n",
    "    f.write(i + '\\t' + yearlyincome + '\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a loop and writing to a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = ['enzoknol', 'officialtrapcity', 'martingarrix', 'rtlthevoice']\n",
    "\n",
    "dat = []\n",
    "\n",
    "for user in users:\n",
    "    url = 'http://www.socialblade.com/youtube/user/'+user\n",
    "    print(url)\n",
    "    browser.get(url)\n",
    "    time.sleep(3) # let the browser wait for a while!\n",
    "    var = browser.find_element_by_css_selector('#socialblade-user-content > div:nth-child(3) > div:nth-child(2) > p:nth-child(1)').text\n",
    "    dat.append({\"user\" : user, \"yearlyincome\": var})\n",
    "\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data to JSON\n",
    "f=open('scraping-output.json', 'w', encoding = 'utf-8')\n",
    "for line in dat:\n",
    "    f.write(json.dumps(line)+'\\n')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or... save the data to CSV\n",
    "f=open('scraping-output.csv', 'w')\n",
    "for line in dat:\n",
    "    f.write(line.get('user')+'\\t'+line.get('yearlyincome')+'\\n')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Scraper with error handling (try-except)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's re-run the cell above, but catch any error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = ['enzoknol', 'officialtrapcity', 'martingarrix', 'rtlthevoice', 'hannesd84']\n",
    "\n",
    "dat = []\n",
    "\n",
    "for user in users:\n",
    "    url = 'http://www.socialblade.com/youtube/user/'+user\n",
    "    browser.get(url)\n",
    "    time.sleep(3) # let the browser wait for a while!\n",
    "    \n",
    "    try:\n",
    "        var = browser.find_element_by_css_selector('#socialblade-user-content > div:nth-child(3) > div:nth-child(2) > p:nth-child(1)').text\n",
    "    except:\n",
    "        var = 'NA'\n",
    "    dat.append({\"user\":user, \"yearlyincome\": var})\n",
    "\n",
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostics: write page to file so that you can view it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = browser.page_source\n",
    "len(content)\n",
    "f = open('socialblade.html','w', encoding='utf-8')\n",
    "f.write(content)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the html in a browser now! \n",
    "\n",
    "To wrap things up, let's close Chrome again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your turn...!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why don't you adapt the script below to be able to capture a site you're interested in?\n",
    "\n",
    "1) First, open Chrome (if you haven't done so!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first open Chrome again\n",
    "browser=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Second, open the desired page, and then use Chrome's developer menu to locate the elements you're interested in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.get('https://www.op.gg/champion/kled/statistics/top')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Check whether you got the right CSS selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = browser.find_element_by_css_selector('body > div.l-wrap.l-wrap--champion > div.l-container > div > div.tabWrap._recognized > div.l-champion-statistics-content.tabItems > div.tabItem.Content.championLayout-overview > div > div.l-champion-statistics-content__main > table.champion-overview__table.champion-overview__table--summonerspell > tbody:nth-child(3) > tr:nth-child(1) > td.champion-overview__stats.champion-overview__stats--pick').text\n",
    "print(var) # pick rates\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Now build the loop by defining your seeds in a list, and put your selectors in it... (why don't you complete the example?!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISCLAIMER: This code is still the example code from above, it does NOT pertain to op.gg.\n",
    "\n",
    "users = ['nijntje', 'nike', 'adidas', 'hannesd84']\n",
    "\n",
    "dat = []\n",
    "\n",
    "f = open('my-scraping-data.csv','w',encoding='utf-8')\n",
    "\n",
    "for user in users:\n",
    "    url = 'http://www.socialblade.com/youtube/user/'+user\n",
    "    browser.get(url)\n",
    "    time.sleep(3) # let the browser wait for a while!!!!!!!\n",
    "    \n",
    "    try:\n",
    "        var = browser.find_element_by_css_selector('#YouTubeUserTopInfoBlock > div:nth-child(4) > span:nth-child(3)').text\n",
    "    except:\n",
    "        var = 'NA'\n",
    "    \n",
    "    f.write(user + '\\t' + var + '\\n')\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Finish the session by closing the browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
